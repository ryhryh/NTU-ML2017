{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding example\n",
    "https://hk.saowen.com/a/d80aa14a501c9f9d225fe2d67f5403bdbba58b9e62b0ff6a1f46f7422e52459e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Well done!\n",
      "[22, 20]\n",
      "-----------\n",
      "Good work\n",
      "[1, 26]\n",
      "-----------\n",
      "Great effort\n",
      "[36, 40]\n",
      "-----------\n",
      "nice work\n",
      "[11, 26]\n",
      "-----------\n",
      "Excellent!\n",
      "[21]\n",
      "-----------\n",
      "Weak\n",
      "[21]\n",
      "-----------\n",
      "Poor effort!\n",
      "[39, 40]\n",
      "-----------\n",
      "not good\n",
      "[25, 1]\n",
      "-----------\n",
      "poor work\n",
      "[39, 26]\n",
      "-----------\n",
      "Could have done better.\n",
      "[24, 12, 20, 28]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "encoded_docs\n",
    "\n",
    "for i in range(10):\n",
    "    print('-----------')\n",
    "    print(docs[i])\n",
    "    print(encoded_docs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 20  0  0]\n",
      " [ 1 26  0  0]\n",
      " [36 40  0  0]\n",
      " [11 26  0  0]\n",
      " [21  0  0  0]\n",
      " [21  0  0  0]\n",
      " [39 40  0  0]\n",
      " [25  1  0  0]\n",
      " [39 26  0  0]\n",
      " [24 12 20 28]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding(50, 8, input_length=4)\n",
    "\n",
    "50 words in a dict\n",
    "\n",
    "4 words in a input sequence\n",
    "\n",
    "one word to a 8dim vector (ex: 1 > [0,0,0,0,0,0,0,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the model\n",
    "input = Input(shape=(4, ))\n",
    "x = Embedding(vocab_size, 8, input_length=4)(input)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=input, outputs=x)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.6919 - acc: 0.6000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 502us/step - loss: 0.6910 - acc: 0.6000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 483us/step - loss: 0.6899 - acc: 0.6000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 459us/step - loss: 0.6888 - acc: 0.6000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 568us/step - loss: 0.6876 - acc: 0.6000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 434us/step - loss: 0.6864 - acc: 0.6000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 477us/step - loss: 0.6852 - acc: 0.6000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 462us/step - loss: 0.6840 - acc: 0.6000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 482us/step - loss: 0.6828 - acc: 0.6000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 438us/step - loss: 0.6816 - acc: 0.6000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 450us/step - loss: 0.6803 - acc: 0.6000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 450us/step - loss: 0.6791 - acc: 0.6000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 456us/step - loss: 0.6779 - acc: 0.6000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 432us/step - loss: 0.6767 - acc: 0.6000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 429us/step - loss: 0.6754 - acc: 0.6000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 423us/step - loss: 0.6742 - acc: 0.6000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 416us/step - loss: 0.6729 - acc: 0.6000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 405us/step - loss: 0.6717 - acc: 0.6000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 415us/step - loss: 0.6704 - acc: 0.6000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 405us/step - loss: 0.6692 - acc: 0.6000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 432us/step - loss: 0.6679 - acc: 0.6000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 436us/step - loss: 0.6666 - acc: 0.6000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 439us/step - loss: 0.6653 - acc: 0.6000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 400us/step - loss: 0.6641 - acc: 0.6000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 457us/step - loss: 0.6628 - acc: 0.6000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 413us/step - loss: 0.6615 - acc: 0.6000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 436us/step - loss: 0.6602 - acc: 0.7000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 434us/step - loss: 0.6588 - acc: 0.7000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 486us/step - loss: 0.6575 - acc: 0.7000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 410us/step - loss: 0.6562 - acc: 0.7000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 442us/step - loss: 0.6549 - acc: 0.7000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 438us/step - loss: 0.6535 - acc: 0.7000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 428us/step - loss: 0.6522 - acc: 0.7000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 410us/step - loss: 0.6508 - acc: 0.7000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 416us/step - loss: 0.6495 - acc: 0.7000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 365us/step - loss: 0.6481 - acc: 0.7000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 408us/step - loss: 0.6467 - acc: 0.7000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 577us/step - loss: 0.6453 - acc: 0.7000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 441us/step - loss: 0.6439 - acc: 0.7000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 490us/step - loss: 0.6425 - acc: 0.7000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 443us/step - loss: 0.6411 - acc: 0.7000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 460us/step - loss: 0.6397 - acc: 0.8000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 424us/step - loss: 0.6383 - acc: 0.8000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 405us/step - loss: 0.6369 - acc: 0.8000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 475us/step - loss: 0.6354 - acc: 0.8000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 404us/step - loss: 0.6340 - acc: 0.8000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 411us/step - loss: 0.6325 - acc: 0.8000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 453us/step - loss: 0.6311 - acc: 0.8000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 480us/step - loss: 0.6296 - acc: 0.8000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 472us/step - loss: 0.6281 - acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06cf48ac88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, \n",
    "          labels, \n",
    "          epochs=50, \n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 20  0  0]\n",
      " [ 1 26  0  0]\n",
      " [36 40  0  0]\n",
      " [11 26  0  0]\n",
      " [21  0  0  0]\n",
      " [21  0  0  0]\n",
      " [39 40  0  0]\n",
      " [25  1  0  0]\n",
      " [39 26  0  0]\n",
      " [24 12 20 28]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5680893 ],\n",
       "       [0.5604374 ],\n",
       "       [0.5384886 ],\n",
       "       [0.57842195],\n",
       "       [0.50213486],\n",
       "       [0.50213486],\n",
       "       [0.48496452],\n",
       "       [0.49553412],\n",
       "       [0.52664924],\n",
       "       [0.3772443 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(padded_docs)\n",
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42756134],\n",
       "       [0.4483724 ],\n",
       "       [0.5582324 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21 for 'good', 20 for 'poor'\n",
    "arr = [[21,21,21,21],\n",
    "       [20,20,20,20],\n",
    "       [36,18,0,0]]\n",
    "arr = np.array(arr)\n",
    "model.predict(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
