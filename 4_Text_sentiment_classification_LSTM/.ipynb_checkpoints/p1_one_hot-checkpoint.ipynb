{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ntumlta.github.io/2017fall-ml-hw4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x(x):\n",
    "    return x.split(' +++$+++ ')[1]\n",
    "\n",
    "def process_y(x):\n",
    "    return x.split(' +++$+++ ')[0]\n",
    "\n",
    "def return_x_y(file_name, dic_size, maxlen):\n",
    "    train = os.path.join(os.getcwd(),'dataset', file_name)\n",
    "    df_train = pd.read_csv(train,header=None, delimiter='\\n')\n",
    "    df_train.columns = ['raw']\n",
    "    df_train['x'] = df_train['raw'].apply(process_x)\n",
    "    df_train['y'] = df_train['raw'].apply(process_y)\n",
    "    \n",
    "    dic_size = dic_size\n",
    "    docs = df_train['x']\n",
    "    x_train = [one_hot(d, dic_size) for d in docs]\n",
    "    \n",
    "    maxlen = maxlen\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    \n",
    "    y_train = np.array(df_train['y'])\n",
    "    \n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size = 20000\n",
    "maxlen = 50\n",
    "# file_name = 'training_label.txt'\n",
    "\n",
    "x_train, y_train = return_x_y('training_label.txt', dic_size, maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0, 18338,  1972,  4274,  8858],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,  9254, 11413,  7470,  1272,  5664, 11413, 17736,\n",
       "         2664,  6489,  1272,  5786,   205],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "        15602, 18978, 15602, 11846,  3434, 16618,  3285,  4820, 12169,\n",
       "         6282, 16743, 11413,   335, 14157]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_train_valid = 1/4\n",
    "num_train = int(x_train.shape[0] * (1-ratio_train_valid))\n",
    "x_train, x_valid = x_train[:num_train], x_train[num_train:]\n",
    "y_train, y_valid = y_train[:num_train], y_train[num_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 50)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(dic_size, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150000 samples, validate on 50000 samples\n",
      "Epoch 1/1\n",
      "150000/150000 [==============================] - 708s 5ms/step - loss: 0.4298 - acc: 0.8024 - val_loss: 0.4453 - val_acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb45040278>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=1,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 50)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_x_test(x):\n",
    "    s = x.find(',') + 1\n",
    "    return x[s:]\n",
    "    \n",
    "\n",
    "path_test = os.path.join(os.getcwd(),'dataset', 'testing_data.txt')\n",
    "df_test = pd.read_csv(path_test,header=0, delimiter='\\n')\n",
    "df_test.columns = ['raw']\n",
    "df_test['x'] = df_test['raw'].apply(process_x_test)\n",
    "\n",
    "docs = df_test['x']\n",
    "x_test = [one_hot(d, dic_size) for d in docs]\n",
    "\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15744862],\n",
       "       [0.05036242],\n",
       "       [0.09199226],\n",
       "       [0.8169295 ],\n",
       "       [0.5628708 ],\n",
       "       [0.88823736],\n",
       "       [0.16074438],\n",
       "       [0.95949924],\n",
       "       [0.8177417 ],\n",
       "       [0.80802715]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict = model.predict(x_test[:10], batch_size=32)\n",
    "predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
