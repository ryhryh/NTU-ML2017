{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    # [3,4] after normalize => [3/5,4/5]\n",
    "\n",
    "    # K.epsilon()) = 10^-7, prevent from dividing by zero\n",
    "    \n",
    "    return x / ( K.sqrt(K.mean(K.square(x))) + K.epsilon() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_84 (Conv2D)           (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,278,151\n",
      "Trainable params: 1,277,255\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('my_model.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 11\n",
      " -------------------------------- 0 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 5.272117\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 5.272117\n",
      " -------------------------------- 1 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 7.364502\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 7.3645005\n",
      " -------------------------------- 2 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 8.0022545\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 8.002254\n",
      " -------------------------------- 3 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 8.801089\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 8.801089\n",
      " -------------------------------- 4 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 9.262961\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 9.26296\n",
      " -------------------------------- 5 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 9.725487\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 9.725487\n",
      " -------------------------------- 6 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 9.97169\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 9.971689\n",
      " -------------------------------- 7 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 10.569632\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 10.56963\n",
      " -------------------------------- 8 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 10.821935\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 10.821936\n",
      " -------------------------------- 9 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 11.18394\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 11.18394\n",
      " -------------------------------- 10 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 11.53057\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 11.530569\n",
      " -------------------------------- 11 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 11.747791\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 11.747791\n",
      " -------------------------------- 12 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 12.104701\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 12.104701\n",
      " -------------------------------- 13 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 12.41998\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 12.419982\n",
      " -------------------------------- 14 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 12.698156\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 12.698156\n",
      " -------------------------------- 15 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 12.892829\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 12.892827\n",
      " -------------------------------- 16 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 13.109234\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 13.109233\n",
      " -------------------------------- 17 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 13.298654\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 13.298654\n",
      " -------------------------------- 18 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 13.569189\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 13.569189\n",
      " -------------------------------- 19 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 13.731911\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 13.731913\n",
      " -------------------------------- 20 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 13.934288\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 13.934286\n",
      " -------------------------------- 21 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 14.132781\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 14.132783\n",
      " -------------------------------- 22 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 14.388424\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 14.388424\n",
      " -------------------------------- 23 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 14.469237\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 14.469235\n",
      " -------------------------------- 24 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 14.806265\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 14.806265\n",
      " -------------------------------- 25 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 14.78904\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 14.789039\n",
      " -------------------------------- 26 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.026163\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.026163\n",
      " -------------------------------- 27 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.153175\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.153175\n",
      " -------------------------------- 28 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.309346\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.309345\n",
      " -------------------------------- 29 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.485078\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.485078\n",
      " -------------------------------- 30 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.577392\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.57739\n",
      " -------------------------------- 31 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.7610235\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.761024\n",
      " -------------------------------- 32 --------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 15.886337\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 15.886339\n",
      " -------------------------------- 33 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.005896\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.005896\n",
      " -------------------------------- 34 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.210756\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.210756\n",
      " -------------------------------- 35 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.375887\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.375889\n",
      " -------------------------------- 36 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.559214\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.559212\n",
      " -------------------------------- 37 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.74753\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.74753\n",
      " -------------------------------- 38 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.858503\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.858503\n",
      " -------------------------------- 39 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 16.991243\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 16.991245\n",
      " -------------------------------- 40 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.144026\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.144026\n",
      " -------------------------------- 41 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.365515\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.365513\n",
      " -------------------------------- 42 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.502396\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.502396\n",
      " -------------------------------- 43 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.608852\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.608852\n",
      " -------------------------------- 44 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.762142\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.762142\n",
      " -------------------------------- 45 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 17.913761\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 17.913763\n",
      " -------------------------------- 46 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.015533\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.015533\n",
      " -------------------------------- 47 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.175531\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.17553\n",
      " -------------------------------- 48 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.331238\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.331238\n",
      " -------------------------------- 49 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.546755\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.546753\n",
      " -------------------------------- 50 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.685934\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.685936\n",
      " -------------------------------- 51 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 18.824097\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 18.824095\n",
      " -------------------------------- 52 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.003046\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.003046\n",
      " -------------------------------- 53 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.110828\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.110826\n",
      " -------------------------------- 54 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.262182\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.262182\n",
      " -------------------------------- 55 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.442553\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.442553\n",
      " -------------------------------- 56 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.573004\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.573004\n",
      " -------------------------------- 57 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.714537\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.714537\n",
      " -------------------------------- 58 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.873089\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.873089\n",
      " -------------------------------- 59 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 19.951393\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 19.951391\n",
      " -------------------------------- 60 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.144917\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.144917\n",
      " -------------------------------- 61 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.292906\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.292906\n",
      " -------------------------------- 62 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.324896\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.324896\n",
      " -------------------------------- 63 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.55168\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.551682\n",
      " -------------------------------- 64 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.685617\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.685617\n",
      " -------------------------------- 65 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.82631\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.82631\n",
      " -------------------------------- 66 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 20.93099\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 20.93099\n",
      " -------------------------------- 67 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.102873\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.10287\n",
      " -------------------------------- 68 --------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.143696\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.143694\n",
      " -------------------------------- 69 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.279776\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.279772\n",
      " -------------------------------- 70 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.42176\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.421759\n",
      " -------------------------------- 71 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.55204\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.552036\n",
      " -------------------------------- 72 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.657486\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.657486\n",
      " -------------------------------- 73 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.80949\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.80949\n",
      " -------------------------------- 74 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 21.982748\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 21.982746\n",
      " -------------------------------- 75 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.077808\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.07781\n",
      " -------------------------------- 76 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.222364\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.222364\n",
      " -------------------------------- 77 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.36739\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.36739\n",
      " -------------------------------- 78 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.465097\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.465097\n",
      " -------------------------------- 79 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.651337\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.651337\n",
      " -------------------------------- 80 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.725662\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.725662\n",
      " -------------------------------- 81 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.77625\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.776253\n",
      " -------------------------------- 82 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 22.919708\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 22.919708\n",
      " -------------------------------- 83 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.050026\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.05003\n",
      " -------------------------------- 84 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.183628\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.183626\n",
      " -------------------------------- 85 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.292341\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.292341\n",
      " -------------------------------- 86 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.486286\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.486282\n",
      " -------------------------------- 87 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.562347\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.562347\n",
      " -------------------------------- 88 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.699408\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.699408\n",
      " -------------------------------- 89 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.816086\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.816086\n",
      " -------------------------------- 90 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 23.959888\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 23.95989\n",
      " -------------------------------- 91 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.074682\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.074684\n",
      " -------------------------------- 92 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.21542\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.215416\n",
      " -------------------------------- 93 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.341587\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.341587\n",
      " -------------------------------- 94 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.463152\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.463152\n",
      " -------------------------------- 95 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.609303\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.609303\n",
      " -------------------------------- 96 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.707594\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.707594\n",
      " -------------------------------- 97 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.839285\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.839283\n",
      " -------------------------------- 98 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 24.985687\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 24.985685\n",
      " -------------------------------- 99 --------------------------------\n",
      "(1, 48, 48, 1)\n",
      "input_img_data.shape (1, 48, 48, 1)\n",
      "layer_output.shape (1, 7, 7, 256)\n",
      "type(layer_output) <class 'numpy.ndarray'> 25.080402\n",
      "_____after gradient acsent_____\n",
      "Current loss value: 25.080399\n"
     ]
    }
   ],
   "source": [
    "filter_index = 11\n",
    "print('Processing filter %d' % filter_index)\n",
    "\n",
    "\n",
    "layer_name = 'conv2d_88'\n",
    "\n",
    "input_img = model.input\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# return a list of gradient tensor\n",
    "grads = K.gradients(loss, [input_img])[0]\n",
    "grads = normalize(grads)\n",
    "\n",
    "# function = K.function([input_img], [loss, grads])\n",
    "function = K.function([input_img], [loss,grads,layer_output])\n",
    "\n",
    "\n",
    "lr = 1.\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "\n",
    "\n",
    "# 128 +/- 10, 138 > value > 118\n",
    "input_img_data = np.random.random((1, img_width, img_height, 1))\n",
    "input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "# we run gradient ascent for 20 steps\n",
    "for i in range(100):\n",
    "    \n",
    "    print(' -------------------------------- %s --------------------------------' %i)\n",
    "    \n",
    "    loss_value, grads_value, layer_output = function([input_img_data])\n",
    "#     loss_value, grads_value = function([input_img_data])\n",
    "\n",
    "    print(grads_value.shape)\n",
    "    print('input_img_data.shape',input_img_data.shape)\n",
    "    print('layer_output.shape',layer_output.shape)\n",
    "    print('type(layer_output)',type(layer_output),np.mean(layer_output[:, :, :, filter_index]))\n",
    "#     print('input_img_data[0,0,0:2]',input_img_data[0,0,0:2])\n",
    "#     print('grads_value[0,0,0:2]',grads_value[0,0,0:2])\n",
    "    \n",
    "    input_img_data = input_img_data + grads_value * lr\n",
    "    \n",
    "    print('_____after gradient acsent_____')\n",
    "#     print('input_img_data',input_img_data[0,0,0:2])\n",
    "    \n",
    "\n",
    "    print('Current loss value:', loss_value)\n",
    "    \n",
    "    if loss_value <= 0.:\n",
    "        # some filters get stuck to 0, we can skip them\n",
    "        break\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7650d42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = deprocess_image(input_img_data[0,:,:,0])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 20))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
